{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D23shHki5_KR",
        "outputId": "eb046ad6-d5e8-4415-9fcd-e3d72551cd47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!pip install lyricsgenius\n",
        "!pip install -U pip\n",
        "!pip install -U dill\n",
        "!pip install -U nltk==3.5b1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lyricsgenius in /usr/local/lib/python3.6/dist-packages (1.8.2)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from lyricsgenius) (4.6.0)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from lyricsgenius) (2.21.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->lyricsgenius) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->lyricsgenius) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->lyricsgenius) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->lyricsgenius) (2019.11.28)\n",
            "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (20.0.2)\n",
            "Requirement already up-to-date: dill in /usr/local/lib/python3.6/dist-packages (0.3.1.1)\n",
            "Requirement already up-to-date: nltk==3.5b1 in /usr/local/lib/python3.6/dist-packages (3.5b1)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from nltk==3.5b1) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from nltk==3.5b1) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from nltk==3.5b1) (7.1.1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk==3.5b1) (4.38.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2huXugIXfZNd",
        "outputId": "c25b2bb8-1478-4914-de3a-a6729041ab12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import lyricsgenius\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "from nltk import sent_tokenize\n",
        "from nltk import tokenize\n",
        "from nltk.tokenize import LineTokenizer\n",
        "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.util import pad_sequence\n",
        "from nltk.util import bigrams\n",
        "from nltk.util import ngrams\n",
        "from nltk.util import everygrams\n",
        "from nltk.lm.preprocessing import pad_both_ends\n",
        "from nltk.lm.preprocessing import flatten\n",
        "from nltk.lm import MLE\n",
        "from nltk.lm import Laplace\n",
        "from nltk.lm import KneserNeyInterpolated\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cULWJubXfe2e",
        "colab": {}
      },
      "source": [
        "genius = lyricsgenius.Genius(\"2-vcV8P3rF4axVmDxH8NW9NB8j3tlT_M69vdKD60To_V7tZB7o8BWfm5uUETQ3Cg\")\n",
        "genius.remove_section_headers = True #We don't need headers\n",
        "genius.skip_non_songs = False \n",
        "genius.excluded_terms = [\"(Remix)\", \"(Live)\"] #Remixes and live records are usually the same as original songs, so we do not need to double lyrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SEuo5G2ZA3mO",
        "outputId": "d14bf9ee-a2a7-4862-cdbe-dbcb04d82820",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        }
      },
      "source": [
        "#Let's start with 50 songs of Oxxxymiron. We can find total of 88 songs, but I've decided to start with 50, because it takes a lot of time to generate text with a big sample\n",
        "artist = genius.search_artist(\"Oxxxymiron\", max_songs=50, sort=\"title\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Searching for songs by Oxxxymiron...\n",
            "\n",
            "Song 1: \"16 Bars Acapella\"\n",
            "Song 2: \"Afterparty (Demo)\"\n",
            "Song 3: \"AI Ogon\"\n",
            "Song 4: \"Amplify and simplify (Freestyle)\"\n",
            "Song 5: \"CCTV\"\n",
            "Song 6: \"Darkside\"\n",
            "Song 7: \"Freestyle #1\"\n",
            "Song 8: \"Ganz Promo Tune\"\n",
            "Song 9: \"Hangover\"\n",
            "Song 10: \"HPL\"\n",
            "Song 11: \"IMPERIVM\"\n",
            "Song 12: \"Intro\"\n",
            "Song 13: \"OXXXYMIRON\"\n",
            "Song 14: \"Russky Cockney\"\n",
            "Song 15: \"Shade 45 Freestyle (Идея)\"\n",
            "Song 16: \"Street Freestyle battle\"\n",
            "Song 17: \"Ultima Thule\"\n",
            "Song 18: \"Unreleased Track\"\n",
            "Song 19: \"Unreleased Track 2\"\n",
            "Song 20: \"Unreleased Track 3\"\n",
            "Song 21: \"Unreleased Track 4\"\n",
            "Song 22: \"XXX SHOP\"\n",
            "Song 23: \"Башня из слоновой кости (Ivory Tower)\"\n",
            "Song 24: \"Биполярочка (Bipolarochka)\"\n",
            "Song 25: \"Больше Бена (Bigga Than Ben)\"\n",
            "Song 26: \"В бульбуляторе (In the Bong)\"\n",
            "Song 27: \"В говне (In Shit)\"\n",
            "Song 28: \"В долгий путь (1 раунд 17ib) (On a Long Journey)\"\n",
            "Song 29: \"Ветер перемен (2 раунд 17ib) (The Wind of Change)\"\n",
            "Song 30: \"Вечный жид (Everlasting Jew)\"\n",
            "Song 31: \"Витязи словоблудия (Уховертка) (The Knights of Verbiage (Earwig))\"\n",
            "Song 32: \"В книге всё было по-другому (4 раунд 17ib) (The Book Had It Different)\"\n",
            "Song 33: \"Волапюк (Volapük)\"\n",
            "Song 34: \"Восточный Мордор (East Mordor)\"\n",
            "Song 35: \"Всего лишь писатель (Just a Writer)\"\n",
            "Song 36: \"В стране женщин (In the country of women)\"\n",
            "Song 37: \"«Где нас нет» (”On the Other Side”)\"\n",
            "Song 38: \"Город под подошвой (City Under the Sole)\"\n",
            "Song 39: \"Город под подошвой (GPP tour version)\"\n",
            "Song 40: \"Девочка Пиздец (Devochka Pizdets) (2011/2012 demo)\"\n",
            "Song 41: \"Девочка Пиздец (Fucked Up Girl)\"\n",
            "Song 42: \"Дело нескольких минут (3 раунд 17ib) (A Matter of Minutes)\"\n",
            "Song 43: \"День физкультурника (Athlete’s Day)\"\n",
            "Song 44: \"Детектор лжи (Lie Detector)\"\n",
            "Song 45: \"До зимы (Before Winter)\"\n",
            "Song 46: \"До сих пор MC (Still MC)\"\n",
            "Song 47: \"Жук в муравейнике (Beetle in an anthill)\"\n",
            "Song 48: \"Интро (Intro II)\"\n",
            "Song 49: \"Йети и дети (Yeti and children)\"\n",
            "Song 50: \"Каменный Век Русской Поэзии (Stone Age of Russian Poetry)\"\n",
            "\n",
            "Reached user-specified song limit (50).\n",
            "Done. Found 50 songs.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "12TBjtrlcm9z",
        "colab": {}
      },
      "source": [
        "# saving the lyrics of 50 songs of Oxxxymiron as .txt file\n",
        "artist.save_lyrics(extension='txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8OS5Uhfjc-aH",
        "colab": {}
      },
      "source": [
        "lyricss = open(\"Lyrics_Oxxxymiron.txt\",\"r\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVlx7GRjkGzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize.treebank import TreebankWordDetokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PIUL2shyxM0W",
        "colab": {}
      },
      "source": [
        "tokenized_text = [list(map(str.lower, word_tokenize(sent))) \n",
        "                  for sent in lyricss]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAKIIY6DNDGi",
        "colab_type": "code",
        "outputId": "a0fac8ec-8115-4425-ef2a-2be43359a76a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(tokenized_text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aZsBp0KUWdKj",
        "colab": {}
      },
      "source": [
        "# Let's define a function that will generate rap\n",
        "def generate_rap (model, num_lines = 5, num_words_in_line = 10, random_seed = 135):\n",
        "  for i in range(num_lines):\n",
        "    content = []\n",
        "    for token in model.generate(num_words_in_line, random_seed=random_seed+i):\n",
        "      if token == '<s>':\n",
        "        continue\n",
        "      if token == '</s>':\n",
        "        break\n",
        "      content.append(token)\n",
        "    content = TreebankWordDetokenizer().detokenize(content)\n",
        "    if bool(content):\n",
        "      i = 0\n",
        "      while not content[i].isalpha():\n",
        "          i += 1\n",
        "          if i > len(content)-1:\n",
        "            break\n",
        "      print(content[i:].capitalize())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NXFpQ9hWSP1f",
        "colab": {}
      },
      "source": [
        "train, test = train_test_split(tokenized_text, test_size=0.2, random_state=135)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_Ztf0HkJfdj",
        "colab_type": "text"
      },
      "source": [
        "##**Unigram** **models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OiiOqekqdA3k",
        "colab": {}
      },
      "source": [
        "#I will use MLE, Laplace and KNI models, and compare them with the perplexity\n",
        "model = MLE(1)\n",
        "train_data, padded_sents = padded_everygram_pipeline(1, train)\n",
        "model.fit(train_data, padded_sents)\n",
        "\n",
        "model1 = Laplace(1)\n",
        "train_data1, padded_sents1 = padded_everygram_pipeline(1, train)\n",
        "model1.fit(train_data1, padded_sents1)\n",
        "\n",
        "model2 = KneserNeyInterpolated(1)\n",
        "train_data2, padded_sents2 = padded_everygram_pipeline(1, train)\n",
        "model2.fit(train_data2, padded_sents2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IJRYwAhYdTLO",
        "outputId": "6d93f579-958c-4a40-85e4-f7ab1a1eb338",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "generate_rap(model, random_seed = 135)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Они неандертальцем на камень социальными, в надо bitch ни\n",
            "Мы ложь и реальными звания? ни, — победою\n",
            "За — бардак господи соты укладывает куда я сюр\n",
            "The и пламя « тления бреду``и говорят пока\n",
            "Пиздец машина у чёрный о простых методик лифт ты\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IAiqiz_zRtl",
        "colab_type": "code",
        "outputId": "de5bcbf6-aeb2-48cb-f907-3bc95e02b0f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "generate_rap(model1, random_seed = 135)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Пара но налит кричишь стань: военкоматы нба loves нужен\n",
            "На мессии из рэп и double нутом, — полна\n",
            "Зови қалай будь джойстике стану успел магомета это так\n",
            "Алёша как подошвой белый только в hah их дела похоже\n",
            "Под мне увижу чтобы оставил районам мои меня у\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_uZkxb31SiN",
        "colab_type": "code",
        "outputId": "840ab6ed-c476-4872-ce68-70b6da5b418a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "generate_rap(model2, random_seed = 135)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Поняли пирсы оставляя мониторов сотру бери дружный отчизне вам плюс\n",
            "Опа недотёпа лето сакмарову курсиву бродяги по left яиц продаёт\n",
            "Still красивый этанол городит изолента сотни тусклой наследил чендлер стенокардийным\n",
            "Всеми любых приму вытащи таблице далёкую бывал ломбарде ибо прохода\n",
            "S придумал неустанно требующая харуки покидаю рифмоваться новой невнятные точно\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-XjP5UeJ9PQ",
        "colab_type": "text"
      },
      "source": [
        "Generated with unigram models text looks more like the a set of words. Let calculate the perplexity for unigrams. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juGuNINcJeiq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data1,_ = padded_everygram_pipeline(1, test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFEbKih1JgXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_gen1 = []\n",
        "\n",
        "for line in test_data1:\n",
        "  test_gen1.extend(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8nXLwZcJkYs",
        "colab_type": "code",
        "outputId": "15a00a77-9c00-461f-ed08-e6e9043bbeaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('MLE unigram model perplexity: {}'.format(model.perplexity(test_gen1)))\n",
        "print('Laplace unigram model perplexity: {}'.format(model1.perplexity(test_gen1)))\n",
        "print('KNI unigram model perplexity: {}'.format(model2.perplexity(test_gen1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLE unigram model perplexity: inf\n",
            "Laplace unigram model perplexity: 1433.9464746295664\n",
            "KNI unigram model perplexity: 6623.999999995705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBBbU_wILZAZ",
        "colab_type": "text"
      },
      "source": [
        "MLE model has the infinite perplexity, and it is true for all MLE models in this data set. The possible explanation that I found is that the is infinite perplexity if  words in test data are out of vocab of train data. Among two other models, Laplace shows better results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8ync6wEMyTi",
        "colab_type": "text"
      },
      "source": [
        "##**Bigram models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXQQE7cf-NGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3 = MLE(2)\n",
        "train_data3, padded_sents3 = padded_everygram_pipeline(2, train)\n",
        "model3.fit(train_data3, padded_sents3)\n",
        "\n",
        "model4 = KneserNeyInterpolated(2)\n",
        "train_data4, padded_sents4 = padded_everygram_pipeline(2, train)\n",
        "model4.fit(train_data4, padded_sents4)\n",
        "\n",
        "model5 = Laplace(2)\n",
        "train_data5, padded_sents5 = padded_everygram_pipeline(2, train)\n",
        "model5.fit(train_data5, padded_sents5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ONhtg1qUCCB8",
        "outputId": "a3a276bc-f98c-4e89-daaf-78fed30ee838",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "generate_rap(model3, random_seed = 135)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "На плите кипятку\n",
            "Их подлости\n",
            "Когда я дон жуан\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ziHfH08mCCCE",
        "outputId": "99c4eee0-e01b-4ad9-9170-1afc7930e103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "generate_rap(model4, random_seed = 135)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Понял все нигеры напоминают пидоров\n",
            "Опа, кто с начала движа гроши, я развиваюсь\n",
            "Start this is back, у тебя мёртвым не способен\n",
            "Вселяют ужас тебя? перелет короткий был зачат дабстеп?\n",
            "S never slowing my whole life on the middle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyTFsaCUC4s3",
        "colab_type": "code",
        "outputId": "ee0d4879-c6d2-4d96-c03c-029dbb0703f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "generate_rap(model5, random_seed = 135)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Нба!\n",
            "Концепт: « погоди, буду резать, ясный хрен\n",
            "Короче\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jobiklGSM9le",
        "colab_type": "text"
      },
      "source": [
        "Using bigram models helps us to get the more connected resluts. The lines and phrases are more coherent. Let's have a look at the perplexity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QK2luAiKR5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data2,_ = padded_everygram_pipeline(2, test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAHhJQTOKR_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_gen2 = []\n",
        "\n",
        "for line in test_data2:\n",
        "  test_gen2.extend(line)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA-IJmB9KSGp",
        "colab_type": "code",
        "outputId": "c733c872-9220-4456-ef2f-c1d13e81fcea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('MLE bigram model perplexity: {}'.format(model3.perplexity(test_gen2)))\n",
        "print('Laplace bigram model perplexity: {}'.format(model5.perplexity(test_gen2)))\n",
        "print('KNI bigram model perplexity: {}'.format(model4.perplexity(test_gen2)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLE bigram model perplexity: inf\n",
            "Laplace bigram model perplexity: 1312.3297697086282\n",
            "KNI bigram model perplexity: 3348.3528586536167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehMdC6okNWil",
        "colab_type": "text"
      },
      "source": [
        "The bigram Laplace model shows better results, than in unigram model (1312 vs 1433). KNI has a very large value of perplexity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEYjUK0RN61h",
        "colab_type": "text"
      },
      "source": [
        "##**Trigram models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzvVR2BsIjR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model6 = MLE(3)\n",
        "train_data6, padded_sents6 = padded_everygram_pipeline(3, train)\n",
        "model6.fit(train_data6, padded_sents6)\n",
        "\n",
        "model7 = Laplace(3)\n",
        "train_data7, padded_sents7 = padded_everygram_pipeline(3, train)\n",
        "model7.fit(train_data7, padded_sents7)\n",
        "\n",
        "model8 = KneserNeyInterpolated(3)\n",
        "train_data8, padded_sents8 = padded_everygram_pipeline(3, train)\n",
        "model8.fit(train_data8, padded_sents8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCjiwjR_Ijd0",
        "colab_type": "code",
        "outputId": "f04bdb15-b3b8-49fc-81a2-32878ef7424f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "generate_rap(model6, random_seed = 135)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Концерты\n",
            "Дам слово, что он властный социопат? »\n",
            "Когда что-то роняют\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o63zlJF2ItOP",
        "colab_type": "code",
        "outputId": "24b44746-dcb8-4359-ff4c-9074db71ee60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "generate_rap(model7, random_seed = 135)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Мандельштамом\n",
            "Ждём кислорода\n",
            "Короче\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVjj5YeRIjcF",
        "colab_type": "code",
        "outputId": "fb69e75c-49a7-4986-ec96-4b96e0627fce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "generate_rap(model8, random_seed = 135)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Понял все трюки на битах\n",
            "Опа, а с виду! »\n",
            "Start this\n",
            "Вселяют ужас и страх, увеселяют фристайлом, став рэп-автоматами\n",
            "S never been\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjYqJJA-OB7V",
        "colab_type": "text"
      },
      "source": [
        "In terms of meaning, bigrams and trigrams are little different. Trigrams produce shorter phrases that are still unconnected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUR8AQPIKp8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data3,_ = padded_everygram_pipeline(3, test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph0wym60KkX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_gen3 = []\n",
        "\n",
        "for line in test_data3:\n",
        "  test_gen3.extend(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aox9QLkgKkbb",
        "colab_type": "code",
        "outputId": "9af7a9f3-b8f6-4a4b-f611-ad2d524fbbdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('MLE trigram model perplexity: {}'.format(model6.perplexity(test_gen3)))\n",
        "print('Laplace trigram model perplexity: {}'.format(model7.perplexity(test_gen3)))\n",
        "print('KNI trigram model perplexity: {}'.format(model8.perplexity(test_gen3)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLE trigram model perplexity: inf\n",
            "Laplace trigram model perplexity: 935.1007539948323\n",
            "KNI trigram model perplexity: 1501.3966443325182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_C1wSptOQjV",
        "colab_type": "text"
      },
      "source": [
        "Nevertheless, the trigram models show the best results for perplexity. Laplace function is still the leader. However, KNI function shows a significantly better results in trigrams than in bigrams.\n",
        "\n",
        "The next step is to get more data and compare the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTfReOlpPCRt",
        "colab_type": "text"
      },
      "source": [
        "#**Getting more data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQcA3y6APIZT",
        "colab_type": "text"
      },
      "source": [
        "I've decided to increase the sample by adding 3 new musicians - Skriptonite, Face and Slava KPSS. I do not really know whether they are similar to Oxxymiron in style and sense, because I am not a rap expert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a5GDbKpBAlb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "genius.remove_section_headers = True\n",
        "genius.skip_non_songs = False \n",
        "genius.excluded_terms = [\"(Remix)\", \"(Live)\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC7Uq0PwKkew",
        "colab_type": "code",
        "outputId": "c9d3fb34-fbb5-4560-ea47-3148b5f32814",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#maximum number of songs for each raper is 50, as it was for Oxxximiron\n",
        "Scr = genius.search_artist(\"Скриптонит\", max_songs=50, sort=\"title\")\n",
        "Face = genius.search_artist(\"FACE\", max_songs=50, sort=\"title\")\n",
        "Slava = genius.search_artist(\"Слава КПСС\", max_songs=50, sort=\"title\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Searching for songs by Скриптонит...\n",
            "\n",
            "Changing artist name to 'Скриптонит (Scriptonite)'\n",
            "Song 1: \"1000\"\n",
            "Song 2: \"100 поцелуев (100 Kisses)\"\n",
            "Song 3: \"104 (Skit)\"\n",
            "Song 4: \"21\"\n",
            "Song 5: \"4 My Town\"\n",
            "Song 6: \"5 здесь 5 там (5 zdes, 5 tam)\"\n",
            "Song 7: \"7182\"\n",
            "Song 8: \"Bad Vision\"\n",
            "Song 9: \"Blunts\"\n",
            "Song 10: \"Damn\"\n",
            "Song 11: \"Go dilla\"\n",
            "Song 12: \"High Volume\"\n",
            "Song 13: \"Na Na Na\"\n",
            "Song 14: \"No Hook\"\n",
            "Song 15: \"No Hook #2\"\n",
            "Song 16: \"No Hook #3 [Траур]\"\n",
            "Song 17: \"Outro\"\n",
            "Song 18: \"Player In C (Cover)\"\n",
            "Song 19: \"PVL Is Back\"\n",
            "Song 20: \"Snippet\"\n",
            "Song 21: \"Supa Dupa\"\n",
            "Song 22: \"VBVVCTND\"\n",
            "Song 23: \"Work\"\n",
            "Song 24: \"Ага, ну (Yeah, well)\"\n",
            "Song 25: \"Больше (More)\"\n",
            "Song 26: \"Братик (Bro)\"\n",
            "Song 27: \"Братик 2 (Bro 2)\"\n",
            "Song 28: \"Бумажки (Paper)\"\n",
            "Song 29: \"Бунт (Bunt)\"\n",
            "Song 30: \"Вечеринка (Party)\"\n",
            "Song 31: \"Витамин (Vitamin)\"\n",
            "Song 32: \"Внатуре (For Real)\"\n",
            "Song 33: \"Вниз (Down)\"\n",
            "Song 34: \"Вчера ночью (Last Night)\"\n",
            "Song 35: \"Выпить тебя до дна (Drink you to the bottom)\"\n",
            "Song 36: \"Выходные (Vyhodnye)\"\n",
            "Song 37: \"Где твоя любовь? (Where is your love?)\"\n",
            "Song 38: \"Дома (At home)\"\n",
            "Song 39: \"Дома делать было нечего (DDBN)\"\n",
            "Song 40: \"Дома нечего делать #2 (DND)\"\n",
            "Song 41: \"До утра (Until Morning)\"\n",
            "Song 42: \"Животные (Animals)\"\n",
            "Song 43: \"Жизненная Перспектива (Life Perspective)\"\n",
            "Song 44: \"Замерз (Froze)\"\n",
            "Song 45: \"Запах из детства (Smell from the childhood)\"\n",
            "Song 46: \"Зеркала (Mirrors)\"\n",
            "Song 47: \"...инсту (...instu)\"\n",
            "Song 48: \"Интервью (Interview)\"\n",
            "Song 49: \"Интро ’15 (Intro ’15)\"\n",
            "Song 50: \"Интро (Intro)\"\n",
            "\n",
            "Reached user-specified song limit (50).\n",
            "Done. Found 50 songs.\n",
            "Searching for songs by FACE...\n",
            "\n",
            "Song 1: \"162\"\n",
            "Song 2: \"24 на 7\"\n",
            "Song 3: \"All Good\"\n",
            "Song 4: \"APRIL  8\"\n",
            "Song 5: \"Baby\"\n",
            "Song 6: \"Baby Face\"\n",
            "Song 7: \"Blazer\"\n",
            "Song 8: \"Enter The Void\"\n",
            "Song 9: \"Forever Young\"\n",
            "Song 10: \"Holiday\"\n",
            "Song 11: \"Ian Connor\"\n",
            "Song 12: \"I dropped Gucci\"\n",
            "Song 13: \"I Hate Humans (Unreleased)\"\n",
            "Song 14: \"Instagram\"\n",
            "Song 15: \"I Want\"\n",
            "Song 16: \"January\"\n",
            "Song 17: \"Kanji\"\n",
            "Song 18: \"Karamel\"\n",
            "Song 19: \"KILL\"\n",
            "Song 20: \"MASK\"\n",
            "Song 21: \"Megan Fox\"\n",
            "Song 22: \"Motorola\"\n",
            "Song 23: \"MURDER\"\n",
            "Song 24: \"My Girls\"\n",
            "Song 25: \"MYSELF\"\n",
            "Song 26: \"MY SQUAD\"\n",
            "Song 27: \"Night Fever\"\n",
            "Song 28: \"PAWS\"\n",
            "Song 29: \"PAYBACK\"\n",
            "Song 30: \"Pokemon Go\"\n",
            "Song 31: \"PSP\"\n",
            "Song 32: \"Pull Up\"\n",
            "Song 33: \"Red Rose\"\n",
            "Song 34: \"Riley\"\n",
            "Song 35: \"Rock Star\"\n",
            "Song 36: \"Sega Mega Drive\"\n",
            "Song 37: \"Skate\"\n",
            "Song 38: \"SLIME\"\n",
            "Song 39: \"SOUTHSIDE BABY\"\n",
            "Song 40: \"Supreme X Vetements\"\n",
            "Song 41: \"Track 01\"\n",
            "Song 42: \"Trend\"\n",
            "Song 43: \"Untitled 01\"\n",
            "Song 44: \"Vans\"\n",
            "Song 45: \"Vlone\"\n",
            "Song 46: \"Vlone (2017)\"\n",
            "Song 47: \"WOOF\"\n",
            "Song 48: \"Yeezy Boost\"\n",
            "Song 49: \"АКСЕССУАР (ACCESSORY)\"\n",
            "Song 50: \"Антидепрессант (Antidepressant)\"\n",
            "\n",
            "Reached user-specified song limit (50).\n",
            "Done. Found 50 songs.\n",
            "Searching for songs by Слава КПСС...\n",
            "\n",
            "Changing artist name to 'Слава КПСС (Slava KPSS)'\n",
            "Song 1: \"0лик (Zero)\"\n",
            "Song 2: \"100 barz (Нахуй всех!)\"\n",
            "Song 3: \"12 мая (12 may)\"\n",
            "Song 4: \"16 проблем (InDaBattle 3 Round 2)\"\n",
            "Song 5: \"18 марта (18th of March)\"\n",
            "Song 6: \"2,5 человека (DSV Battle Round 1)\"\n",
            "Song 7: \"30 новых авто (30 New Cars)\"\n",
            "Song 8: \"30 новых авто (30 new cars) [Alternative version]\"\n",
            "Song 9: \"5500\"\n",
            "Song 10: \"Black Stalin\"\n",
            "Song 11: \"BLUNTCUT\"\n",
            "Song 12: \"Burlit\"\n",
            "Song 13: \"Comeback\"\n",
            "Song 14: \"CUCKOLDINI\"\n",
            "Song 15: \"Donbass\"\n",
            "Song 16: \"FACE DISS (FACEFVCK)\"\n",
            "Song 17: \"Grime Thing\"\n",
            "Song 18: \"KIBERDEMON FREESTULE\"\n",
            "Song 19: \"King Ring (Freestyle)\"\n",
            "Song 20: \"MONEY TALK\"\n",
            "Song 21: \"MotorollaPhonk\"\n",
            "Song 22: \"NBA\"\n",
            "Song 23: \"NIKOLAEV CHALLENGE\"\n",
            "Song 24: \"NO, THANKS\"\n",
            "Song 25: \"OLD FRESHMANS DISS\"\n",
            "Song 26: \"One Love\"\n",
            "Song 27: \"Red widow\"\n",
            "Song 28: \"Rickey F diss challenge\"\n",
            "Song 29: \"S.B.U\"\n",
            "Song 30: \"SKY-FRAUD.RU (Кардеры)\"\n",
            "Song 31: \"Slavyansk\"\n",
            "Song 32: \"#SLOVOSPB\"\n",
            "Song 33: \"SPECIFIC FOR RAPPERS WORDS\"\n",
            "Song 34: \"TEKKEN\"\n",
            "Song 35: \"The Sopranos\"\n",
            "Song 36: \"TOYOTA CRESTA\"\n",
            "Song 37: \"Unknown Track\"\n",
            "Song 38: \"VEGAN БУРГЕР\"\n",
            "Song 39: \"Versus Zoo\"\n",
            "Song 40: \"VODA\"\n",
            "Song 41: \"Xvtt diss\"\n",
            "Song 42: \"XXL FRESHMENS DISS\"\n",
            "Song 43: \"Агитация пессимизма (Agitation of pessimism)\"\n",
            "Song 44: \"Адрес надежды (HHNation.kg Prospect Battle Round 2) (vs. Kilavit)\"\n",
            "Song 45: \"Алёшка Карамазов (Aleshka Karamazov)\"\n",
            "Song 46: \"Алхимия (Alhimiya) [Бутер Бродский]\"\n",
            "Song 47: \"АНАНАСОВАЯ GIRL (PINEAPPLE GIRL)\"\n",
            "Song 48: \"АНАРХОПУТИН (ANARHOPUTIN)\"\n",
            "Song 49: \"Ангелки (Angels)\"\n",
            "Song 50: \"Аниме Гангрейв (Anime Gungrave)\"\n",
            "\n",
            "Reached user-specified song limit (50).\n",
            "Done. Found 50 songs.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZf-XIZhM5Yj",
        "colab_type": "code",
        "outputId": "8aad1c81-d153-4373-c848-e9dcf6bad723",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "Scr.save_lyrics(extension='txt')\n",
        "Face.save_lyrics(extension='txt')\n",
        "Slava.save_lyrics(extension='txt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wrote `Lyrics_СкриптонитScriptonite.txt`\n",
            "Wrote `Lyrics_FACE.txt`\n",
            "Wrote `Lyrics_СлаваКПССSlavaKPSS.txt`\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-uKtA8_M5fb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Slava_lyr= open(\"Lyrics_СлаваКПССSlavaKPSS.txt\",\"r\")\n",
        "Scr_lyr = open(\"Lyrics_СлаваКПССSlavaKPSS.txt\",\"r\")\n",
        "Face_lyr = open(\"Lyrics_FACE.txt\",\"r\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w73V_5CTM5il",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Slava_tokenized = [list(map(str.lower, word_tokenize(sent))) \n",
        "                  for sent in Slava_lyr]\n",
        "Scr_tokenized = [list(map(str.lower, word_tokenize(sent))) \n",
        "                  for sent in Scr_lyr]\n",
        "Face_tokenized = [list(map(str.lower, word_tokenize(sent))) \n",
        "                  for sent in Face_lyr]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OIPzTUpM5lv",
        "colab_type": "code",
        "outputId": "10ebd046-b172-4f78-ebc2-b5eb0060bc94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lyrics = [] #setting one list for all 4 musicians\n",
        "lyrics.extend(tokenized_text)\n",
        "lyrics.extend(Slava_tokenized)\n",
        "lyrics.extend(Scr_tokenized)\n",
        "lyrics.extend(Face_tokenized)\n",
        "print(len(lyrics))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10699\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTFcNW93M5qn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = train_test_split(lyrics, test_size=0.25, random_state=135)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CKviiXCQr4R",
        "colab_type": "text"
      },
      "source": [
        "## **Unigram models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pYZn0tfM5om",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MLE(1)\n",
        "train_data, padded_sents = padded_everygram_pipeline(1, train)\n",
        "model.fit(train_data, padded_sents)\n",
        "\n",
        "model1 = Laplace(1)\n",
        "train_data1, padded_sents1 = padded_everygram_pipeline(1, train)\n",
        "model1.fit(train_data1, padded_sents1)\n",
        "\n",
        "model2 = KneserNeyInterpolated(1)\n",
        "train_data2, padded_sents2 = padded_everygram_pipeline(1, train)\n",
        "model2.fit(train_data2, padded_sents2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PL1sqgBPaVH",
        "colab_type": "code",
        "outputId": "6c8ff952-756f-40e9-c7d3-9f52ecfa48e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "generate_rap(model, random_seed = 135)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Она не на клешни стиль, вам навальный? нету\n",
            "Мы людей и русский знает . ни, — поводу\n",
            "За – бесплатный грустная стерёг фанатки ледовым я тараканов\n",
            "Tonight иди плазмой а тот будто: и гордо помесь\n",
            "Пиздатый меня уже шмотье нынче пьедестал мне любим увидел\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfGQKTU-PaYT",
        "colab_type": "code",
        "outputId": "8a84c693-6645-4879-d884-8baeda1310d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "generate_rap(model1, random_seed = 135)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Пара но налит кричишь стань: военкоматы нба loves нужен\n",
            "На мессии из рэп и double нутом, — полна\n",
            "Зови қалай будь джойстике стану успел магомета это так\n",
            "Алёша как подошвой белый только в hah их дела похоже\n",
            "Под мне увижу чтобы оставил районам мои меня у\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFZ9ZDCzPabp",
        "colab_type": "code",
        "outputId": "d3b2b959-749a-4d3c-801a-d3491556e4a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "generate_rap(model2, random_seed = 135)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Поставить плывущих отыграл мс сплифом болезней ебём парку вес подкрепление\n",
            "Отдали неприятны лечить свалил кыргызстан бэттлиться поднял original ядерный проснешься\n",
            "Yeezy кроватку эрнесто грязная иремель сплетению убогий нацист чендлер странной\n",
            "Вынимать майонез продолжаю гликодин творец дерьма ввысь-ввысь лучший изнутри путь\n",
            "Но проблемах ногами туз хейтер помог ротацию обернулся нему трусы-неделька\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yURjFwI7Pael",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data1,_ = padded_everygram_pipeline(1, test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hUVweNwPah0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_gen1 = []\n",
        "\n",
        "for line in test_data1:\n",
        "  test_gen1.extend(line)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP9tyAnpPanE",
        "colab_type": "code",
        "outputId": "11d8499d-1740-4bd3-db3d-4854b2a43fc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('MLE unigram model perplexity: {}'.format(model.perplexity(test_gen1)))\n",
        "print('Laplace unigram model perplexity: {}'.format(model1.perplexity(test_gen1)))\n",
        "print('KNI unigram model perplexity: {}'.format(model2.perplexity(test_gen1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLE unigram model perplexity: inf\n",
            "Laplace unigram model perplexity: 1504.3992866843134\n",
            "KNI unigram model perplexity: 11983.99999998177\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6jh8JmOQ8rb",
        "colab_type": "text"
      },
      "source": [
        "Compared to unigram models built only on Oxxxymiron lyrics, these models show higher results, so it means that using more data gets our models a liitle bit worse for understanding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsUqkU3FRdhU",
        "colab_type": "text"
      },
      "source": [
        "##**Bigram models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRfFb4mFPawl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3 = MLE(2)\n",
        "train_data3, padded_sents3 = padded_everygram_pipeline(2, train)\n",
        "model3.fit(train_data3, padded_sents3)\n",
        "\n",
        "model4 = KneserNeyInterpolated(2)\n",
        "train_data4, padded_sents4 = padded_everygram_pipeline(2, train)\n",
        "model4.fit(train_data4, padded_sents4)\n",
        "\n",
        "model5 = Laplace(2)\n",
        "train_data5, padded_sents5 = padded_everygram_pipeline(2, train)\n",
        "model5.fit(train_data5, padded_sents5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slIOCvZ_P_IJ",
        "colab_type": "code",
        "outputId": "5ae82343-2181-474c-a475-9ba76eedef8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "generate_rap(model3, random_seed = 135)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "На площадке\n",
            "Интелекта снижены\n",
            "Копоть\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rf8cEsxP_pa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b4922b20-a25a-4307-9140-b23bfe1f2de5"
      },
      "source": [
        "generate_rap(model4, random_seed = 135)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Поставит на отпуск мы сами брахманы\n",
            "Отдай мне не с небес и похуй) — серп\n",
            "Ya, я высоко, фристайл за пазухой, чем\n",
            "Вынесено\n",
            "Но ты не теряю счёт\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiBGgwjkP_nh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7987a482-ec26-4a73-9ef4-94e91b6ee92e"
      },
      "source": [
        "generate_rap(model5, random_seed = 135)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Нба!\n",
            "Концепт: « погоди, буду резать, ясный хрен\n",
            "Короче\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns9xZgDSP_e2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data2,_ = padded_everygram_pipeline(2, test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rBXhuHdP_dE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_gen2 = []\n",
        "\n",
        "for line in test_data2:\n",
        "  test_gen2.extend(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7lgPZQxP_bb",
        "colab_type": "code",
        "outputId": "f8130be7-d58b-4db3-e539-f5ca1920dcbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('MLE bigram model perplexity: {}'.format(model3.perplexity(test_gen2)))\n",
        "print('Laplace bigram model perplexity: {}'.format(model5.perplexity(test_gen2)))\n",
        "print('KNI bigram model perplexity: {}'.format(model4.perplexity(test_gen2)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLE bigram model perplexity: inf\n",
            "Laplace bigram model perplexity: 1272.2152578934601\n",
            "KNI bigram model perplexity: 2040.6538711956744\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8_2eAXrRpo9",
        "colab_type": "text"
      },
      "source": [
        "These results are better, than for bigram models for a smaller dataset. The best model is Laplace one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-F1S9NAtRzrf",
        "colab_type": "text"
      },
      "source": [
        "##**Trigram models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daJvuSYHP_S2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model6 = MLE(3)\n",
        "train_data6, padded_sents6 = padded_everygram_pipeline(3, train)\n",
        "model6.fit(train_data6, padded_sents6)\n",
        "\n",
        "model7 = Laplace(3)\n",
        "train_data7, padded_sents7 = padded_everygram_pipeline(3, train)\n",
        "model7.fit(train_data7, padded_sents7)\n",
        "\n",
        "model8 = KneserNeyInterpolated(3)\n",
        "train_data8, padded_sents8 = padded_everygram_pipeline(3, train)\n",
        "model8.fit(train_data8, padded_sents8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCXdbUJ0P_RL",
        "colab_type": "code",
        "outputId": "00bad0c9-096c-4a4e-90e9-6558d6739f5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "generate_rap(model6, random_seed = 15)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Китайцев\n",
            "Гордо течет (гордо течет (гордо течет [?\n",
            "Копоть\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V12pGX-oPa8b",
        "colab_type": "code",
        "outputId": "bcbcdf1d-79d7-421e-d030-b8647f4bc29d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "generate_rap(model7, random_seed = 15)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ы) да\n",
            "Каждый квартал check, словно оборотень\n",
            "Выкини коленце, в стойбище прет жеребёнок\n",
            "Метро как анаконда и жёлтая дорожка\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hK78DJ7TPa6X",
        "colab_type": "code",
        "outputId": "53e259ea-6ee4-469b-fbe2-ca19dcf05f39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "generate_rap(model8, random_seed = 135)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Поставит на репит музыку сфер\n",
            "Отдай мне злато\n",
            "Ya, ya, ya\n",
            "Вынесено\n",
            "Но ты ведь так хотел\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUrwGiJuQkH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data3,_ = padded_everygram_pipeline(3, test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d5Oi0elQkSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_gen3 = []\n",
        "\n",
        "for line in test_data3:\n",
        "  test_gen3.extend(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igl4LlqbPalR",
        "colab_type": "code",
        "outputId": "84a57c4a-c5cb-4f0f-e3f2-287fae716ea7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('MLE trigram model perplexity: {}'.format(model6.perplexity(test_gen3)))\n",
        "print('Laplace trigram model perplexity: {}'.format(model7.perplexity(test_gen3)))\n",
        "print('KNI trigram model perplexity: {}'.format(model8.perplexity(test_gen3)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLE trigram model perplexity: inf\n",
            "Laplace trigram model perplexity: 875.6413284752927\n",
            "KNI trigram model perplexity: 585.7741052536325\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIdK21oCR8Fz",
        "colab_type": "text"
      },
      "source": [
        "The trigram models for a big dataset shave shown the best results for the whole work. Surprisingly, the KNI perplexity is several time lower than for smaller dataset. So, we can conclude that the KNI trigram model with the bigger dataset is the best choice for this case. From the point of view of sense, the result of this model is also could be considered as something more or less reasonable."
      ]
    }
  ]
}
